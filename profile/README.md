# ðŸ”¥ðŸ”¥ðŸ”¥Expediting Large-Scale Vision Transformer for Dense Prediction without Fine-tuning, NeurIPS 2022

[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2210.01035)
![visitors](https://visitor-badge.glitch.me/badge?page_id=Expedit-LargeScale-Vision-Transformer&left_color=blue&right_color=green)

## News

**2023.04.13** Code for [Expedit-SAM](https://github.com/Expedit-LargeScale-Vision-Transformer/Expedit-SAM) is released. We elegantly expedite `Segment Anything Model (SAM)` by using our method without any training.

**2023.03.24** Code for [Expedit-DINO](https://github.com/Expedit-LargeScale-Vision-Transformer/Expedit-DINO) is released.

**2023.03.21** Codes for [Expedit-Segmenter](https://github.com/Expedit-LargeScale-Vision-Transformer/Expedit-Segmenter), [Expedit-SWAG](https://github.com/Expedit-LargeScale-Vision-Transformer/Expedit-SWAG), and [Expedit-DPT](https://github.com/Expedit-LargeScale-Vision-Transformer/Expedit-DPT) are released.

**2022.10.03** "Expediting Large-Scale Vision Transformer for Dense Prediction without Fine-tuning" has been released to arXiv. 

**2022.09.15** "Expediting Large-Scale Vision Transformer for Dense Prediction without Fine-tuning" has been accepted at NeurIPS 2022. ðŸŽ‰ðŸŽ‰ðŸŽ‰


## Introduction

![poster](profile/nips_poster.png)

## Citation
If you find this work useful in your research, please consider citing:
```bibtex
@article{liang2022expediting,
  title={Expediting large-scale vision transformer for dense prediction without fine-tuning},
  author={Liang, Weicong and Yuan, Yuhui and Ding, Henghui and Luo, Xiao and Lin, Weihong and Jia, Ding and Zhang, Zheng and Zhang, Chao and Hu, Han},
  journal={arXiv preprint arXiv:2210.01035},
  year={2022}
}
```


